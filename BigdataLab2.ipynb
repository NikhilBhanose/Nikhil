{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikhilBhanose/Nikhil/blob/main/BigdataLab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 2\n",
        "* Bhanose Nikhil Rajesh\n",
        "* Sd-202318016"
      ],
      "metadata": {
        "id": "4TDRSmU3kNqL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lp-7J29Eyn7O"
      },
      "outputs": [],
      "source": [
        "import sklearn as sk\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "data=fetch_20newsgroups(subset = \"train\")\n",
        "(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(data.data)\n",
        "vectorizer.get_feature_names_out()\n",
        "print(X)"
      ],
      "metadata": {
        "id": "cKxvLQbSAPjP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8679ca1-569f-496a-82d5-b3a4bbd8f536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 86580)\t0.13157118714240987\n",
            "  (0, 128420)\t0.04278499079283093\n",
            "  (0, 35983)\t0.03770448563619875\n",
            "  (0, 35187)\t0.09353930598317124\n",
            "  (0, 66098)\t0.09785515708314481\n",
            "  (0, 114428)\t0.05511105154696676\n",
            "  (0, 78955)\t0.05989856888061599\n",
            "  (0, 94362)\t0.055457031390147224\n",
            "  (0, 76722)\t0.06908779999621749\n",
            "  (0, 57308)\t0.1558717009157704\n",
            "  (0, 62221)\t0.02921527992427867\n",
            "  (0, 128402)\t0.05922294083277842\n",
            "  (0, 67156)\t0.07313443922740179\n",
            "  (0, 123989)\t0.08207027465330353\n",
            "  (0, 90252)\t0.031889368795417566\n",
            "  (0, 63363)\t0.08342748387969037\n",
            "  (0, 78784)\t0.0633940918806495\n",
            "  (0, 96144)\t0.10826904490745741\n",
            "  (0, 128026)\t0.060622095889758885\n",
            "  (0, 109271)\t0.10844724822064673\n",
            "  (0, 51730)\t0.09714744057976722\n",
            "  (0, 86001)\t0.07000411445838192\n",
            "  (0, 83256)\t0.08844382496462173\n",
            "  (0, 113986)\t0.17691750674853082\n",
            "  (0, 37565)\t0.03431760442478462\n",
            "  :\t:\n",
            "  (11313, 87626)\t0.041237139601784885\n",
            "  (11313, 30044)\t0.03581554412880591\n",
            "  (11313, 76377)\t0.0635841806495367\n",
            "  (11313, 119714)\t0.05924995560199499\n",
            "  (11313, 47982)\t0.04878764010149914\n",
            "  (11313, 28146)\t0.04703946070749562\n",
            "  (11313, 88363)\t0.13916610283479094\n",
            "  (11313, 56283)\t0.026074886321515986\n",
            "  (11313, 111695)\t0.08039375842219382\n",
            "  (11313, 90252)\t0.03304599951634829\n",
            "  (11313, 51730)\t0.10067098834752665\n",
            "  (11313, 68766)\t0.026413823187147637\n",
            "  (11313, 89860)\t0.029615670644273114\n",
            "  (11313, 80638)\t0.0409862722594402\n",
            "  (11313, 4605)\t0.06562288156075427\n",
            "  (11313, 76032)\t0.019916554974882542\n",
            "  (11313, 89362)\t0.022525659920776243\n",
            "  (11313, 90379)\t0.020651681778766563\n",
            "  (11313, 64095)\t0.03670564487644039\n",
            "  (11313, 95162)\t0.035721664777432695\n",
            "  (11313, 87620)\t0.03696568532482317\n",
            "  (11313, 111322)\t0.019851534178948714\n",
            "  (11313, 85354)\t0.03831068303611253\n",
            "  (11313, 50527)\t0.056595152440003904\n",
            "  (11313, 56979)\t0.03970306835789743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 and 3\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def tfidf_vectorizer(docs):\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "\n",
        "\n",
        "    tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "\n",
        "    return vectorizer, tfidf_matrix\n",
        "\n",
        "def cosine_similarity_matrix(tfidf_matrix):\n",
        "\n",
        "    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "def document_similarity_search(input_doc, vectorizer, tfidf_matrix, docs):\n",
        "\n",
        "    input_vector = vectorizer.transform([input_doc])\n",
        "\n",
        "\n",
        "    similarities = cosine_similarity(input_vector, tfidf_matrix).flatten()\n",
        "\n",
        "\n",
        "    ranked_documents = sorted(enumerate(similarities), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "\n",
        "    doc_indices, scores = zip(*ranked_documents)\n",
        "\n",
        "\n",
        "    ranked_docs = [docs[i] for i in doc_indices]\n",
        "\n",
        "    return ranked_docs, scores\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
        "    documents = newsgroups.data\n",
        "\n",
        "\n",
        "    input_document = \"20 news group\"\n",
        "\n",
        "\n",
        "    vectorizer, tfidf_matrix = tfidf_vectorizer(documents)\n",
        "\n",
        "\n",
        "    similar_documents, similarity_scores = document_similarity_search(input_document, vectorizer, tfidf_matrix, documents)\n",
        "\n",
        "\n",
        "    print(\"Input Document:\")\n",
        "    print(input_document)\n",
        "    print(\"\\nTop 5 Similar Documents:\")\n",
        "    for i in range(5):\n",
        "        print(f\"Similarity Score: {similarity_scores[i]:.4f}\")\n",
        "        print(similar_documents[i])\n",
        "        print(\"----------------------\")"
      ],
      "metadata": {
        "id": "GQT1v8z8C9Px",
        "outputId": "ceaea7d8-103c-4885-e284-f00d50e5909d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Document:\n",
            "20 news group\n",
            "\n",
            "Top 5 Similar Documents:\n",
            "Similarity Score: 0.3543\n",
            "\n",
            "Please post to news, too.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "----------------------\n",
            "Similarity Score: 0.2856\n",
            "\n",
            "Where did that idea come from?  It's news to me.\n",
            "----------------------\n",
            "Similarity Score: 0.2575\n",
            "Once upon a time, long long ago in this news group, someone\n",
            "posted a schematic for a 1-bit A/D converter.  Well I just found a use\n",
            "for the little monster.  Anyone out there still got this text file?\n",
            "It had a flip-flop, a resistor and a cap, and a comparator/op-amp I \n",
            "think.  I would be extremely thankful to anyone who could mail me the \n",
            "schematic or post it to the news-group.\n",
            "\n",
            "\n",
            "\n",
            "----------------------\n",
            "Similarity Score: 0.2438\n",
            "Hello netters\n",
            "\n",
            "Sorry, I don't know if this is the right way of doing this kind of thing,\n",
            "probably should be a CFV, but since I don't have tha ability to create a \n",
            "news group myself, I just want to start the discussion. \n",
            "\n",
            "I enjoy reading c.g very much, but I often find it difficult to sort out what\n",
            "I'm interested in. Everything from screen-drivers, graphics cards, graphics\n",
            "programming and graphics programs are discused here. What I'd like is a \n",
            "comp.graphics.programmer news group.\n",
            "What do you other think.\n",
            "\n",
            "----------------------\n",
            "Similarity Score: 0.2355\n",
            "FYI...I just posted this on alt.psychoactives as a response to\n",
            "what the group is for......\n",
            "\n",
            "\n",
            "A note to the users of alt.psychoactives....\n",
            "\n",
            "This group was originally a takeoff from sci.med.  The reason for\n",
            "the formation of this group was to discuss prescription psychoactive\n",
            "drugs....such as antidepressents(tri-cyclics, Prozac, Lithium,etc),\n",
            "antipsychotics(Melleral(sp?), etc), OCD drugs(Anafranil, etc), and\n",
            "so on and so forth.  It didn't take long for this group to degenerate\n",
            "into a psudo alt.drugs atmosphere.  That's to bad, for most of the\n",
            "serious folks that wanted to start this group in the first place have\n",
            "left and gone back to sci.med, where you have to cypher through\n",
            "hundreds of unrelated articles to find psychoactive data.\n",
            "\n",
            "It was also to discuss real-life experiences and side effects of\n",
            "the above mentioned.\n",
            "\n",
            "Oh well, I had unsubscribed to this group for some time, and I decided\n",
            "to check it today to see if anything had changed....nope....same old\n",
            "nine or ten crap articles that this group was never intended for.\n",
            "\n",
            "I think it is very hard to have a meaningfull group without it\n",
            "being moderated...too bad.\n",
            "\n",
            "Oh well, obviously, no one really cares.\n",
            "\n",
            "Bill Claussen\n",
            "\n",
            "\n",
            "Would anyone be interested in starting a similar moderated group?\n",
            "----------------------\n"
          ]
        }
      ]
    }
  ]
}